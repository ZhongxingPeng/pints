{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions and notation for Pints\n",
    "\n",
    "This document is:\n",
    "\n",
    "1. An attempt to write down some standard notation for Pints\n",
    "2. A place to stick derivations of stuff used in Pints (e.g. loglikelihoods, not optimiser or sampling algorithms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of symbols\n",
    "\n",
    "Please stick to the symbols below when editing this document.\n",
    "\n",
    "| Description                 | Mathematical version     | Code version          |\n",
    "|-----------------------------|--------------------------|-----------------------|\n",
    "| Time                        | $t$, $t_i$               | `times`               |\n",
    "| Observations (values)       | $v$, $v_i$               | `values`              |\n",
    "| Time series (data)          | $D$                      |                       |\n",
    "| Number of times/values      | $n_t$                    | `n_times`             |\n",
    "| Parameters                  | $x$, $x_i$               | `x`, `parameters`     |\n",
    "| Number of parameters        | $n_p$                    | `n_parameters`, `n_p` |\n",
    "| Forward model               | $m(t|x)$                 | `model`               |\n",
    "| Forward model values        | $m_i(x) = m(t_i|x)$      | `y`                   |\n",
    "| Number of model outputs     | $n_o$                    | `n_outputs`, `n_o`    |\n",
    "| PDF                         | $f(D|x)$                 |                       |\n",
    "| Likelihood                  | $l(x|D)$ or $l(x)$       |                       |\n",
    "| LogPDF                      |                          | `logpdf`              |\n",
    "| Loglikelihood               | $L(x)$                   | L                     |\n",
    "\n",
    "Prior?\n",
    "Logposterior?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem statement\n",
    "\n",
    "We have some noisy time-series data and a forward model (simulation) that can be used to replicate it.\n",
    "We'd like to find out which parameter values are compatible with the experimental evidence.\n",
    "\n",
    "- Observations $D = \\{(t_1, v_1),...,(t_{n_t}, v_{n_t})\\}$ where $v_i$ is the experimental measurement at time $t_i$, and the times are ordered $t_{i + 1} >= t_i$, with $i = 1, 2, ..., n_t$.\n",
    "\n",
    "- A forward model $m(t|x)$ that takes a time $t$ as input, as well as a parameter vector $x$ of length $n_p$.\n",
    "\n",
    "- Observations can be scalars, or vectors of some fixed length $n_o$. If vector outputs are used, the forward model must also produce $n_o$ _outputs_. In general, this means $v \\in {\\rm I\\!R}^{n_o}$ and $m(t|x) \\to {\\rm I\\!R}^{n_o}$.\n",
    "\n",
    "Often, but not always\n",
    "\n",
    "- The parameters live in some bounded space $x \\in X \\subset{\\rm I\\!R}^{n_p}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Noise/error models\n",
    "\n",
    "If we assume the model can perfectly describe the data with the correct parameters, we can interpret the remaining error as noise.\n",
    "If we have a probabilistic model for this noise, we can then write a probability density function (PDF) for the probability of a model with parameters $x$ generating the observations $D$:\n",
    "\n",
    "$$ f(D|x) $$\n",
    "\n",
    "We can rewrite this as a likelihood:\n",
    "\n",
    "$$ l(x|D) \\equiv f(D|x) $$\n",
    "\n",
    "As it turns out, it's usually easier to work with the natural logarithm of this function instead.\n",
    "\n",
    "$$ L(x|D) = \\log l(x|D)$$\n",
    "\n",
    "which we'll often shorten to\n",
    "\n",
    "$$ L(x) $$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normally distributed independent noise\n",
    "\n",
    "In this section, we derive a loglikelihood for a parameter vector $x$ assuming normally distributed noise, that is independent from observation to observation.\n",
    "\n",
    "We start by looking at single-output models, and assume our noise is from a Normal distribution with mean 0 and standard distribution $\\sigma$.\n",
    "For now we'll assume we have some way of knowing $\\sigma$, e.g. by doing an independent measurement.\n",
    "\n",
    "We can then treat our observations as random variables of the form (model prediction + Gausian noise):\n",
    "\n",
    "$$ V_i \\sim m_i(x) + \\mathcal{N}(0, \\sigma^2) = \\mathcal{N}(m_i(x), \\sigma^2)$$\n",
    "\n",
    "Filling in the equation for the normal distribution, we find\n",
    "\n",
    "$$ f_i(v_i | x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\n",
    "                  \\left( -\\frac{ \\left( m_i(x) - v_i \\right)^2}{2\\sigma^2} \\right) $$\n",
    "\n",
    "The independent noise assumption then gives\n",
    "\n",
    "$$ f(D | x) = \\prod_{i=1}^{n_t} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\n",
    "              \\left( -\\frac{ \\left( m_i(x) - v_i \\right)^2}{2\\sigma^2} \\right) $$\n",
    "\n",
    "To find $L(x)$ we use $L(x) = L(x|D) = \\log l(x|D) = \\log f(D|x)$:\n",
    "\n",
    "$$ L(x) = \n",
    "    - \\frac{n_t}{2} \\log(2\\pi)\n",
    "    - n_t \\log(\\sigma)\n",
    "    - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n_t} \\left(m_i(x) - v_i \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Multiple outputs\n",
    "\n",
    "To find a multi-output version, we define the observation in output $j$ at time $i$ as $v_{ij}$. The equivalent model variable is $m_{ij}(x)$.\n",
    "\n",
    "If we assume that the noise in any one output is independent from the noise in the others, we can write the total log-likelihood of the observations as the sum of the loglikelihoods in each output:\n",
    "\n",
    "$$ L(x) = \\sum_{j=1}^{n_o} L_j(x) $$\n",
    "$$ L(x) = \\sum_{j=1}^{n_o} - \\frac{n_t}{2} \\log(2\\pi)\n",
    "                           - n_t \\log(\\sigma)\n",
    "                           - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n_t} \\left(m_i(x) - v_i \\right)^2\n",
    "$$\n",
    "$$ L(x) = - \\frac{n_t n_o}{2} \\log(2\\pi) \n",
    "          - n_t \\sum_{j=1}^{n_o} \\log(\\sigma_j)\n",
    "          - \\sum_{j=1}^{n_o} \\left[ \\frac{1}{2\\sigma_j^2} \\sum_{i=1}^{n_t} \\left(m_{ij}(x) - v_{ij} \\right)^2 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Derivatives with respect to the parameters\n",
    "\n",
    "The partial derivatives with respect to parameter $x_k$, evaluated at $x$ are written as\n",
    "\n",
    "$$ \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_x $$\n",
    "\n",
    "For the independent normal loglikelihood, we then find\n",
    "\n",
    "$$ \\left. \\frac{\\partial L}{\\partial x_k} \\right|_x =\n",
    "    \\sum_{j=1}^{n_o} \\left[ \\frac{1}{\\sigma_j^2} \\sum_{i=1}^{n_t}\n",
    "    \\left(v_{ij} - m_{ij}(x) \\right) \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_x \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Unknown noise: treating $\\sigma$ as a parameter\n",
    "\n",
    "If we don't have accurate information about $\\sigma$, we can try treating it as a parameter an infering it along with the others.\n",
    "In code, we'll do this by simply extending $x$ to include $\\sigma$.\n",
    "In the descriptions below, we'll leave $\\sigma$ separate for clarity.\n",
    "\n",
    "The normal independent log-likelihood becomes:\n",
    "\n",
    "$$ L(x, \\sigma) = - \\frac{n_t n_o}{2} \\log(2\\pi) \n",
    "          - n_t \\sum_{j=1}^{n_o} \\log(\\sigma_j)\n",
    "          - \\sum_{j=1}^{n_o} \\left[ \\frac{1}{2\\sigma_j^2} \\sum_{i=1}^{n_t} \\left(m_{ij}(x) - v_{ij} \\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "where $x$ is the original parameter vector $x_1, x_2, ..., x_{n_p}$ and $\\sigma$ is a vector of the standard deviations in each output $\\sigma_1, \\sigma_2, ..., \\sigma_{n_o}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Derivatives\n",
    "\n",
    "For the derivatives, we now find $n_p$ equations of the previous form:\n",
    "\n",
    "$$ \\left. \\frac{\\partial L}{\\partial x_k} \\right|_{x, \\sigma} =\n",
    "    \\sum_{j=1}^{n_o} \\left[ \\frac{1}{\\sigma_j^2} \\sum_{i=1}^{n_t}\n",
    "    \\left(v_{ij} - m_{ij}(x) \\right) \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_{x, \\sigma} \\right]\n",
    "$$\n",
    "\n",
    "where $k \\in 1, 2, ..., n_p$.\n",
    "In addition, we get $n_o$ equations:\n",
    "\n",
    "$$ \\left. \\frac{\\partial L}{\\partial x_m} \\right|_{x, \\sigma} =\n",
    "    - n_t / \\sigma_m\n",
    "    + \\sigma_m^{-3} \\sum_{i=1}^{n_t} \\left(m_{im}(x) - v_{im} \\right)^2\n",
    "$$\n",
    "\n",
    "where $m \\in 1, 2, ..., n_o$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error measures\n",
    "\n",
    "All error measures implement some measure $E(x)$ that is minimised at $E(x_\\text{true})$, but is otherwise completely unrestrained in its values, smoothness, etc.\n",
    "\n",
    "Any LogLikelihood can be made into an error measure by reversing it's sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sum of squares\n",
    "\n",
    "One of the simplest error measures is\n",
    "\n",
    "$$ E(x) = \\sum_{i=1}^{n_t} \\left( m_i(x) - v_i \\right)^2 $$\n",
    "\n",
    "For multiple outputs, all weighted equally, this becomes\n",
    "\n",
    "$$ E(x) = \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \\left( m_{ij}(x) - v_{ij} \\right)^2 $$\n",
    "\n",
    "For its derivative, we find\n",
    "\n",
    "$$ \\left. \\frac{\\partial E}{\\partial x_k} \\right|_x = \n",
    "    2 \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \n",
    "    \\left( m_{ij}(x) - v_{ij} \\right)\n",
    "    \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Weighted sum of squares\n",
    "\n",
    "We can scale the error in each output by introducing weighing factors $w_j$ for $j \\in 1, 2, ..., n_o$.\n",
    "\n",
    "This isn't implemented at the moment!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Mean squared error\n",
    "\n",
    "In some cases, it can be desirable to make the error invariant to the length of the sample $n_t$.\n",
    "\n",
    "$$ E(x) = \\frac{1}{n_t} \\sum_{i=1}^{n_t} \\left( m_i(x) - v_i \\right)^2 $$\n",
    "\n",
    "For multiple outputs, all weighted equally, this becomes\n",
    "\n",
    "$$ E(x) = \\frac{1}{n_t n_o} \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \\left( m_{ij}(x) - v_{ij} \\right)^2 $$\n",
    "\n",
    "For its derivative, we find\n",
    "\n",
    "$$ \\left. \\frac{\\partial E}{\\partial x_k} \\right|_x = \n",
    "\\frac{2}{n_t n_o} \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \n",
    "    \\left( m_{ij}(x) - v_{ij} \\right)\n",
    "    \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Root-mean squared error\n",
    "\n",
    "A common error measure is\n",
    "\n",
    "$$ E(x) = \\sqrt{ \\frac{1}{n_t} \\sum_{i=1}^{n_t} \\left( m_i(x) - v_i \\right)^2 } $$\n",
    "\n",
    "For multiple outputs, all weighted equally, this becomes\n",
    "\n",
    "$$ E(x) = \\sqrt{  \\frac{1}{n_t n_o} \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \\left( m_{ij}(x) - v_{ij} \\right)^2 } $$\n",
    "\n",
    "For its derivative, we find\n",
    "\n",
    "$$ \\left. \\frac{\\partial E}{\\partial x_k} \\right|_x = \n",
    "    \\frac{\n",
    "        \\frac{2}{n_t n_o} \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \n",
    "        \\left( m_{ij}(x) - v_{ij} \\right)\n",
    "        \\left. \\frac{\\partial m_{ij}}{\\partial x_k} \\right|_x\n",
    "    }{\n",
    "        \\sqrt{ \\frac{1}{n_t n_o} \\sum_{j=1}^{n_o} \\sum_{i=1}^{n_t} \\left( m_{ij}(x) - v_{ij} \\right)^2 }\n",
    "    }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
